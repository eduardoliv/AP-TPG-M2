{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706d0b52",
   "metadata": {},
   "source": [
    "### Notebook: Tracking de mãos e instrumentos – Tarefa 3 OSS 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e483d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Instalar bibliotecas\n",
    "# -------------------------------------------------------------\n",
    "# %pip install -q ultralytics==8.1.0 opencv-python==4.9.0.80 torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578243ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Importações e configuração geral\n",
    "# -------------------------------------------------------------\n",
    "import cv2\n",
    "import torch\n",
    "import json\n",
    "import gc\n",
    "\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "ROOT = Path.cwd() / 'Task3'\n",
    "print(ROOT)\n",
    "DATA_DIR = ROOT / 'data'\n",
    "OUT_DIR = ROOT / 'outputs'\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Definições\n",
    "TRACKER_CFG = dict(track_thresh=0.6,\n",
    "                   match_thresh=0.9,\n",
    "                   track_buffer=30,\n",
    "                   mot20=False)\n",
    "\n",
    "# YOLO Image Size\n",
    "IMGSZ = 1920\n",
    "\n",
    "# Tracker Max Age\n",
    "TRACKER_MAX_AGE = 5\n",
    "\n",
    "# Classes a considerar (mapeamento simples de COCO)\n",
    "VALID_CLS = {0: \"hand\", 43: \"instrument\"}    # 0: person ~ mão, 43: scissors ~ instrumento\n",
    "\n",
    "# Definir GPU como device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Dispositivo: \" + device)\n",
    "\n",
    "# Libertar memória da GPU\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9957a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# Tracker simples por IoU em PyTorch puro\n",
    "# -----------------------------------------------------------------\n",
    "class SimpleIoUTracker:\n",
    "    def __init__(self, iou_threshold=0.3, max_age=5):\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.max_age = max_age\n",
    "        self.tracks = {}  # id: (bbox_tensor, age)\n",
    "        self.next_id = 0\n",
    "\n",
    "    def _iou(self, box1, box2):\n",
    "        x1 = torch.max(box1[0], box2[0])\n",
    "        y1 = torch.max(box1[1], box2[1])\n",
    "        x2 = torch.min(box1[2], box2[2])\n",
    "        y2 = torch.min(box1[3], box2[3])\n",
    "        inter_area = torch.clamp(x2 - x1, min=0) * torch.clamp(y2 - y1, min=0)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union_area = area1 + area2 - inter_area\n",
    "        return inter_area / union_area\n",
    "\n",
    "    def update(self, detections):\n",
    "        updated_tracks = {}\n",
    "        assigned = set()\n",
    "        for tid, (prev_bbox, age) in self.tracks.items():\n",
    "            best_iou = self.iou_threshold\n",
    "            best_det = None\n",
    "            for i, det in enumerate(detections):\n",
    "                if i in assigned:\n",
    "                    continue\n",
    "                iou = self._iou(prev_bbox, det)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_det = i\n",
    "            if best_det is not None:\n",
    "                updated_tracks[tid] = (detections[best_det], 0)\n",
    "                assigned.add(best_det)\n",
    "            elif age + 1 <= self.max_age:\n",
    "                updated_tracks[tid] = (prev_bbox, age + 1)\n",
    "\n",
    "        for i, det in enumerate(detections):\n",
    "            if i not in assigned:\n",
    "                updated_tracks[self.next_id] = (det, 0)\n",
    "                self.next_id += 1\n",
    "\n",
    "        self.tracks = updated_tracks\n",
    "        return self.tracks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119aa5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# Detecção + tracking de um vídeo; devolve caminho do JSON gerado\n",
    "# -----------------------------------------------------------------\n",
    "def process_video(video_path: Path, model, out_dir: Path, valid_cls={0, 43}, frame_step=30, conf_thresh=0.15):\n",
    "    video_id = video_path.stem\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Erro ao abrir vídeo: {video_path}\")\n",
    "\n",
    "    tracker = SimpleIoUTracker(max_age=TRACKER_MAX_AGE)\n",
    "    frame_id = 0\n",
    "    tracks = {}\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        if frame_id % frame_step != 0:\n",
    "            frame_id += 1\n",
    "            continue\n",
    "\n",
    "        h, w = frame.shape[:2]\n",
    "        detections_tensor = []\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                res = model(frame, conf=conf_thresh, imgsz=IMGSZ)[0]\n",
    "                boxes = res.boxes\n",
    "                if boxes and boxes.xyxy.numel() > 0:\n",
    "                    xyxy = boxes.xyxy.to(\"cpu\")\n",
    "                    confs = boxes.conf.to(\"cpu\")\n",
    "                    clss = boxes.cls.to(\"cpu\")\n",
    "                    mask = torch.tensor([int(c.item()) in valid_cls for c in clss])\n",
    "                    xyxy = xyxy[mask]\n",
    "                    confs = confs[mask]\n",
    "                    for box, conf in zip(xyxy, confs):\n",
    "                        if conf.item() >= conf_thresh:\n",
    "                            detections_tensor.append(box)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERRO] YOLO falhou no frame {frame_id}: {e}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            frame_id += 1\n",
    "            continue\n",
    "\n",
    "        det_tensor = torch.stack(detections_tensor) if detections_tensor else torch.empty((0, 4), dtype=torch.float32)\n",
    "        frame_tracks = tracker.update(det_tensor)\n",
    "        for tid, (bbox, _) in frame_tracks.items():\n",
    "            x1, y1, x2, y2 = bbox.tolist()\n",
    "            bbox_json = [float(x1), float(y1), float(x2), float(y2)]\n",
    "            tracks.setdefault(str(frame_id), []).append({\n",
    "                \"id\": int(tid), \"bbox\": bbox_json, \"score\": 1.0\n",
    "            })\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        frame_id += 1\n",
    "\n",
    "    cap.release()\n",
    "    out_path = out_dir / f\"{video_id}.json\"\n",
    "    with open(out_path, \"w\") as fp:\n",
    "        json.dump(tracks, fp, indent=2)\n",
    "    print(f\"[INFO] JSON gravado: {out_path}\")\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Detecção e segmentação com YOLOv8\n",
    "# -------------------------------------------------------------\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "json_paths = []\n",
    "for mp4 in DATA_DIR.glob(\"*.mp4\"):\n",
    "    print(f\"Processar {mp4.name}\")\n",
    "    json_paths.append(process_video(mp4, model, OUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ce1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Função para sobrepor caixas + IDs e gravar novo .mp4\n",
    "# -------------------------------------------------------------\n",
    "def annotate_video(video_path: Path, json_path: Path, out_dir: Path, max_age=5) -> Path:\n",
    "    vid_id   = video_path.stem\n",
    "    out_path = out_dir / f\"{vid_id}_tracked.mp4\"\n",
    "\n",
    "    with open(json_path) as fp:\n",
    "        preds = json.load(fp)\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps  = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(str(out_path), fourcc, fps, (w, h))\n",
    "\n",
    "    f_idx = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        for frame_offset in range(0, -max_age, -1):\n",
    "            past_frame = str(f_idx + frame_offset)\n",
    "            for obj in preds.get(past_frame, []):\n",
    "                x1, y1, x2, y2 = map(int, obj['bbox'])\n",
    "                tid = obj['id']\n",
    "                colour = ((tid*37)%255, (tid*17)%255, (tid*97)%255)\n",
    "                alpha = 1.0 if frame_offset == 0 else 0.4  # mais esbatido\n",
    "                overlay = frame.copy()\n",
    "                cv2.rectangle(overlay, (x1,y1), (x2,y2), colour, 2)\n",
    "                cv2.putText(overlay, f'ID {tid}', (x1, y1-5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, colour, 1, cv2.LINE_AA)\n",
    "                frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
    "\n",
    "        writer.write(frame)\n",
    "        f_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    print(f\"Vídeo anotado: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "# Gerar vídeo anotado para cada par vídeo/JSON\n",
    "for mp4, js in zip(DATA_DIR.glob(\"*.mp4\"), json_paths):\n",
    "    annotate_video(mp4, js, OUT_DIR, max_age=TRACKER_MAX_AGE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
